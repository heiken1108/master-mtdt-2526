{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Sequence-based Person Clustering\n",
    "Ønsker å clustere personer basert på oppførsels-mønsteret de viser fra konto-dataen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "figsize=(14, 4)\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import file, plot, data, stat\n",
    "pd.set_option('display.max_columns', None)\n",
    "data_folder = os.path.join('../../..', 'data/prod')\n",
    "file_name_collection = \"Collection_data.csv\"\n",
    "file_path_collection = os.path.join(data_folder, file_name_collection)\n",
    "file_name_konto = \"konto_data_trimmed.csv\"\n",
    "file_path_konto = os.path.join(data_folder, file_name_konto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "konto_frame, collection_frame = file.load_konto_data(file_path_konto), file.load_collection_data(file_path_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "konto_frame['BalanceAmt'].max(), konto_frame['BalanceAmt'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_frame[collection_frame[\"PersonId\"] == 84].head(40)\n",
    "#collection_frame.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "interesting_column = \"TurnoverNum\"\n",
    "first_n_ids = konto_frame[\"PersonId\"].unique()[:n]\n",
    "dfs = []\n",
    "for i in first_n_ids:\n",
    "\tdf_person = konto_frame[konto_frame[\"PersonId\"] == i][[\"PersonId\", interesting_column]].reset_index(drop=True)\n",
    "\t#df_person[interesting_column] = df_person[interesting_column] * -1\n",
    "\tdf_person = stat.z_normalize(df_person, interesting_column)\n",
    "\tdfs.append(df_person)\n",
    "#plot.multi_linear_step_plot(dfs, interesting_column, \"PersonId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "pairwise_similarity_stepwise er O(n^2 * m) hvor n er antall personer og m er lengden på sekvensen. `symmetric_matrix`= False halverer antall operasjoner. Men minnebruket blir det samme uansett. Det lagres en float på hver posisjon, og å lagre som nan har ingen påvirkning\n",
    "\n",
    "| n    | Tid (s) | Minne |\n",
    "|------|----------|-------|\n",
    "| 100  | 0.0s     | 78.9 KB   |\n",
    "| 200  | 0.3s     |  314.1 KB  |\n",
    "| 250  | 0.5s     |  490.2 KB  |\n",
    "| 300  | 0.7s     |  705.5 KB  |\n",
    "| 400  | 1.2s     |  1.2 MB  |\n",
    "| 500  | 1.9s     |  1.9 MB  |\n",
    "| 750  | 4.3s     |  4.3 MB  |\n",
    "| 1000 | 7.9s     |   7.6 MB |\n",
    "| 1250 | 12.6s    |  11.9 MB  |\n",
    "| 1500 | 17.7s    |  17.2 MB  |\n",
    "| 2000 | 31.8s    |  30.5 MB  |\n",
    "| 2500 | 50.0s    |  47.7 MB  |\n",
    "| 3000 | 1m 12.5s |  68.7 MB  |\n",
    "| 5000 | 7m 14.7s (kanskje scuffed) | 190.8 MB   |\n",
    "| 10000 | 40m 16.5s (kanskje scuffed) | 763 MB |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df = stat.pairwise_similarity_stepwise(dfs, value_col=interesting_column, id_col=\"PersonId\", symmetric_matrix=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.heatmap_plot(sim_df, drop_0=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = konto_frame[konto_frame[\"PersonId\"] == 1359][interesting_column].reset_index(drop=True)\n",
    "s2 = konto_frame[konto_frame[\"PersonId\"] == 2065][interesting_column].reset_index(drop=True)\n",
    "\n",
    "# Combine into a DataFrame\n",
    "df_side_by_side = pd.DataFrame({\n",
    "    \"First sequence\": s1,\n",
    "    \"Second sequence\": s2\n",
    "})\n",
    "\n",
    "df_side_by_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "konto_frame[konto_frame[\"PersonId\"] == 1501][interesting_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Multi-column stepwise similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['BalanceAmt', 'TurnoverAmt', 'TurnoverNum', 'OverdueAmt', 'StatementEffectivePaymentsAmt']\n",
    "id_col = \"PersonId\"\n",
    "n = 30\n",
    "first_n_ids = konto_frame[id_col].unique()[:n]\n",
    "sim_dfs = []\n",
    "for col in cols:\n",
    "\tcol_dfs = []\n",
    "\tfor i in first_n_ids:\n",
    "\t\tdf_person = konto_frame[konto_frame[id_col] == i][[id_col, col]].reset_index(drop=True)\n",
    "\t\tdf_person = stat.z_normalize(df_person, col)\n",
    "\t\tcol_dfs.append(df_person)\n",
    "\tsim_df = stat.pairwise_similarity_stepwise(col_dfs, value_col=col, id_col=id_col, symmetric_matrix=False)\n",
    "\tsim_dfs.append(sim_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, val in enumerate(sim_dfs):\n",
    "\tplot.heatmap_plot(val, title=cols[i], drop_0=True)\n",
    "avg_df = sum(sim_dfs) / len(sim_dfs)\n",
    "plot.heatmap_plot(avg_df, title=\"Average\", drop_0=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into a DataFrame\n",
    "df_side_by_side = pd.DataFrame({\n",
    "    \"First sequence\": konto_frame[konto_frame[id_col] == 1365][\"StatementEffectivePaymentsAmt\"].reset_index(drop=True),\n",
    "    \"Second sequence\": konto_frame[konto_frame[id_col] == 1605][\"StatementEffectivePaymentsAmt\"].reset_index(drop=True)\n",
    "})\n",
    "\n",
    "df_side_by_side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_frame['Status'] = np.where(collection_frame['CollectionClosedDate'].isna(), 'PENDING', 'COMPLETED')\n",
    "collection_frame = collection_frame.groupby(['PersonId'], as_index=False).tail(1)\n",
    "collection_frame['Loss'] = (collection_frame['CumulativeLossAmt']/collection_frame['BalanceSentAmt'] * 100).round(2)\n",
    "collection_frame[\"LossBool\"] = (collection_frame[\"Loss\"] > 0).astype(int)\n",
    "collection_frame[[\"PersonId\", \"Loss\"]].sort_values(by=[\"Loss\"], ascending=False).head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_frame[collection_frame[\"PersonId\"] == 794010].head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_frame = collection_frame[collection_frame[\"PersonId\"].isin(first_n_ids)][[\"PersonId\", \"LossBool\"]]\n",
    "col_frame.head(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = avg_df.copy()\n",
    "np.fill_diagonal(matrix.values, np.nan)\n",
    "stacked = matrix.unstack().dropna()\n",
    "stacked = stacked.sort_values(ascending=False)\n",
    "top10 = stacked.head(n)\n",
    "top10_df = top10.reset_index()\n",
    "top10_df.columns = ['person1', 'person2', 'correlation']\n",
    "\n",
    "print(top10_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = (\n",
    "    top10_df\n",
    "    .merge(col_frame.rename(columns={'PersonId': 'person1', 'LossBool': 'LossBool1'}), on='person1', how='left')\n",
    "    .merge(col_frame.rename(columns={'PersonId': 'person2', 'LossBool': 'LossBool2'}), on='person2', how='left')\n",
    ")\n",
    "\n",
    "# Add a boolean column: True if both have same LossBool value\n",
    "merged['SameLossBool'] = merged['LossBool1'] == merged['LossBool2']\n",
    "\n",
    "merged.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['cumulative_accuracy'] = merged['SameLossBool'].expanding().mean() * 100  # in %\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, len(merged) + 1), merged['cumulative_accuracy'], marker='o')\n",
    "plt.title('Accuracy of SameLossBool vs. Number of Top Correlations')\n",
    "plt.xlabel('Number of Top Correlation Pairs (N)')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
